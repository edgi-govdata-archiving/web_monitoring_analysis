{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘gridExtra’\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    combine\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(readr) #if not already installed, install.packages(\"readr\")\n",
    "library(openxlsx) #if not already installed, install.packages(\"openxlsx\")\n",
    "library(dplyr) # etc.\n",
    "library(ggplot2)\n",
    "library(ggrepel)\n",
    "library(gridExtra)\n",
    "library(viridis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsed with column specification:\n",
      "cols(\n",
      "  .default = col_integer()\n",
      ")\n",
      "See spec(...) for full column specifications.\n",
      "Parsed with column specification:\n",
      "cols(\n",
      "  .default = col_integer()\n",
      ")\n",
      "See spec(...) for full column specifications.\n",
      "Parsed with column specification:\n",
      "cols(\n",
      "  .default = col_character()\n",
      ")\n",
      "See spec(...) for full column specifications.\n",
      "Parsed with column specification:\n",
      "cols(\n",
      "  `url - o` = col_character(),\n",
      "  `shortened url - o` = col_character(),\n",
      "  `captured url - 0` = col_character(),\n",
      "  `url - t` = col_character(),\n",
      "  `shortened url - t` = col_character(),\n",
      "  `final captured url - t` = col_character(),\n",
      "  domain = col_character(),\n",
      "  org = col_character()\n",
      ")\n",
      "Parsed with column specification:\n",
      "cols(\n",
      "  .default = col_integer()\n",
      ")\n",
      "See spec(...) for full column specifications.\n",
      "Parsed with column specification:\n",
      "cols(\n",
      "  .default = col_integer(),\n",
      "  X1 = col_character()\n",
      ")\n",
      "See spec(...) for full column specifications.\n"
     ]
    }
   ],
   "source": [
    "#main\n",
    "#load in the first timeframe's data - in this case, Obama era counts\n",
    "first <- read_csv(\"https://raw.githubusercontent.com/edgi-govdata-archiving/web_monitoring_research/r/data/obama_count_r.csv\", col_names = FALSE) \n",
    "#load in the second timeframe's data - in this case, Trump era counts\n",
    "second <- read_csv(\"https://raw.githubusercontent.com/edgi-govdata-archiving/web_monitoring_research/r/data/trump_count_r.csv\", col_names = FALSE) \n",
    "\n",
    "#convert missing values (999) due to WM error to NAs\n",
    "#first[first==999] <- NA\n",
    "#second[second==999] <- NA\n",
    "\n",
    "#load in a CSV that has the list of terms - this is for formatting outputs\n",
    "terms<-read_csv(\"https://raw.githubusercontent.com/edgi-govdata-archiving/web_monitoring_research/r/data/terms.csv\", col_names = FALSE) \n",
    "terms<-tolower(terms)\n",
    "\n",
    "colnames(first)<-terms\n",
    "colnames(second)<-terms\n",
    "\n",
    "urls <- read_csv(\"https://raw.githubusercontent.com/edgi-govdata-archiving/web_monitoring_research/r/data/counted_urls.csv\") \n",
    "#slashes removed means trailing slashes - those at the end of some urls - have been removed #(\"inputs/counted_urls.csv\") #load in a CSV that has a list of the URLs, organizations, etc. #STANDARD SLASHES\n",
    "#_slashes_removed\n",
    "\n",
    "## RECOUNTS\n",
    "# add in recounts - OBAMA\n",
    "recounts <- read_csv(\"https://raw.githubusercontent.com/edgi-govdata-archiving/web_monitoring_research/r/data/2016BLM-DOE-OSHA_counts.csv\", col_names = FALSE)\n",
    "tt<-append(terms, \"index\", after=0)\n",
    "colnames(recounts)<-tt\n",
    "for (org in c(\"DOE\", \"BLM\", \"OSHA\")){\n",
    "  urls_recounts<-which(urls$org==org)\n",
    "  recounts_selected<-recounts[recounts$index %in% urls_recounts,] #subset to selected org\n",
    "  first[c(urls_recounts),]<-recounts_selected[,2:57]\n",
    "}\n",
    "# Do a manual recount for selected DOE pages and term ('efficiency'). Extra 4 uses on many DOE pages in Obama era.\n",
    "# find urls that include \"energy.gov/eere\"\n",
    "urls.manual<-grep('energy.gov/eere', urls$`url - o`)\n",
    "# subtract 4 for navbar and footer counts\n",
    "first[c(urls.manual),'efficiency']<-first[c(urls.manual),'efficiency']-4\n",
    "\n",
    "# add in recounts - TRUMP\n",
    "recounts <- read_csv(\"https://raw.githubusercontent.com/edgi-govdata-archiving/web_monitoring_research/r/data/2018BLM-DOE-OSHA_counts.csv\", col_names = FALSE)\n",
    "tt<-append(terms, \"index\", after=0)\n",
    "colnames(recounts)<-tt\n",
    "for (org in c(\"DOE\", \"BLM\", \"OSHA\")){\n",
    "  urls_recounts<-which(urls$org==org)\n",
    "  recounts_selected<-recounts[recounts$index %in% urls_recounts,] #subset to selected org\n",
    "  second[c(urls_recounts),]<-recounts_selected[,2:57]\n",
    "} \n",
    "write_csv(first, \"obama_count.csv\")\n",
    "write_csv(second, \"trump_count.csv\")\n",
    "# delete the above RECOUNTS and just load it...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this does matrix math to calculate, for each page and term, the change (positive, negative, or zero) in usage\n",
    "combined<-second-first \n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PROCESSING\n",
    "## Handle duplicated URLs - find their \"index\"....\n",
    "duplicates<-which(duplicated(urls$`url - o`) | duplicated(urls$`url - o`, fromLast = TRUE)) #url duplicates\n",
    "duplicates.short<-which(duplicated(urls$`shortened url - o`) | duplicated(urls$`shortened url - o`, fromLast = TRUE))#shortened url duplicates\n",
    "duplicates<-c(duplicates, duplicates.short)\n",
    "duplicates<-unique(duplicates)\n",
    "\n",
    "#....and then filter away\n",
    "first<-first[-c(duplicates),]\n",
    "second<-second[-c(duplicates),]\n",
    "combined<-combined[-c(duplicates),]\n",
    "urls<-urls[-c(duplicates),]\n",
    "\n",
    "## Handle pages we don't want (e.g. Jan 2017 snapshots, blogs, Spanish-language pages)\n",
    "pages.snapshots<-grep('snapshot', urls$`url - o`)\n",
    "pages.edu<-grep('edu/', urls$`url - o`)\n",
    "pages.news<-grep('news', urls$`url - o`)\n",
    "pages.blog<-grep('blog', urls$`url - o`)\n",
    "pages.News<-grep('News', urls$`url - o`)\n",
    "pages.espanol<-grep('espanol', urls$`url - o`)\n",
    "\n",
    "pages.length<-sapply(gregexpr(\"/\", urls$`url - o`), length) # gets the number of slashes in each url (a proxy for importance/relevance)\n",
    "pages.length<-which(pages.length > 6) # remove pages greater than 6 slashes. arbitrary, but remember that every url will have at least 3 slashes - http://wwww.epa.gov/.... 2 in the \"removed slashes\" file\n",
    "#2987 URLs > 4 3-4 http://www.epa.gov/theme/ http://www.epa.gov/theme http://www.epa.gov/ \n",
    "#2314 URLs NOT 5 or NOT 6 5-6  http://www.epa.gov/theme/subtheme/page http://www.epa.gov/theme/subtheme/page/ http://www.epa.gov/theme/subtheme 5 OR 6\n",
    "#296 URLs 7 < 7 http://www.epa.gov/theme/subtheme/page/subpage http://www.epa.gov/theme/subtheme/page/subpage/subsubpage\n",
    "#http://www.epa.gov/theme/subtheme/page/ is max\n",
    "# default is > 6\n",
    "# for page depth analysis > 4 gets \"2 or less\" . getting rid of urls with 5 or more slashes. \n",
    "# for page depth analysis < = 4 gets 3 or more. getting rid of urls with four or fewer\n",
    "\n",
    "dump<-c(pages.snapshots,pages.edu, pages.news,pages.blog, pages.News, pages.espanol, pages.length)\n",
    "dump<-unique(dump)\n",
    "\n",
    "first<-first[-c(dump),]\n",
    "second<-second[-c(dump),]\n",
    "combined<-combined[-c(dump),]\n",
    "urls<-urls[-c(dump),]\n",
    "\n",
    "##compare only on snapshots in both timeframes\n",
    "snaps<-which(!is.na(urls$`captured url - 0`) & !is.na(urls$`final captured url - t`))\n",
    "first<-first[c(snaps),]\n",
    "second<-second[c(snaps),]\n",
    "combined<-combined[c(snaps),]\n",
    "urls<-urls[c(snaps),]\n",
    "\n",
    "##compare only on available counts (disregard NAs/999s)\n",
    "nas<-which(is.na(first[,1])|is.na(second[,1]))\n",
    "first<-first[-c(nas),]\n",
    "second<-second[-c(nas),]\n",
    "combined<-combined[-c(nas),]\n",
    "urls<-urls[-c(nas),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optional filter to only climate-related pages\n",
    "#filter our list to only those pages concerning the \"climate\" topic - that is, where the Obama version mentioned \"climate\" \"climate change\" or \"GHG\"\n",
    "#cc<-which(first[,'climate']>0 | first[,'climate change']>0 | first[,'greenhouse gases']>0) # page indices where Obama used these terms\n",
    "#cc<-which(first[,'climate change']>0) # page indices where Obama used these terms\n",
    "\n",
    "#first<-first[c(cc),]\n",
    "#second<-second[c(cc),]\n",
    "#combined<-combined[c(cc),]\n",
    "#urls<-urls[c(cc),]\n",
    "\n",
    "## co-changes/page-specific changes for termX->termY\n",
    "#Pages where costs increased and benefits decreased\n",
    "#Pages where emissions decreased and air quality increased\n",
    "#pages where climate change decreased and resilience increased\n",
    "#pages where climate change decreased and sustainability increased\n",
    "\n",
    "#filter<-which(combined[,'climate']>0 & combined[,'climate change']<0)\n",
    "#first.filter<-first[c(filter),]\n",
    "#second.filter<-second[c(filter),]\n",
    "#combined.filter<-combined[c(filter),]\n",
    "#urls.filter<-urls[c(filter),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DEBUG\n",
    "##verify obama and trump urls match\n",
    "errors=0\n",
    "for (i in 1:nrow(urls)) {\n",
    "  if (tolower(urls$`shortened url - o`[i]) != tolower(urls$`shortened url - t`[i])){\n",
    "    errors<-errors+1\n",
    "    print(i)\n",
    "  }\n",
    "}\n",
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FIGURE 4\n",
    "# again, this could be done in a loop to compare multiple terms, but for our purposes, we'll look at \"climate change\"\n",
    "i=9\n",
    "\n",
    "#\"Delta chart\" by term...FIGURE PG 14\n",
    "df<-data.frame(first[,i], second[,i])\n",
    "colnames(df)<-c(\"obama\", \"trump\")\n",
    "change<-which(df$obama != 0 | df$trump != 0) #REMOVE ZEROS - we don't want to plot pages that didn't change\n",
    "df<-df[c(change),]\n",
    "df$change <- df$trump-df$obama\n",
    "df.unique<-df %>% group_by(obama, change)%>%mutate(chg = sum(change), count=n()) #%>%mutate(count = n()) # count of unique count pairings by URLs. (1,2 | 1,4 | 3,1 | etc.) How many of each change 1->2, 1->4, 3->1 are there?\n",
    "df.unique<-unique(df.unique)\n",
    "pal <- c(\"red\", \"blue\")\n",
    "p<-ggplot(df.unique, aes(obama, change, alpha=count, fill=change>0)) +\n",
    "geom_bar(stat='identity', position='dodge') +\n",
    "scale_fill_manual(values=pal) +\n",
    "labs(title = 'Changes to the use of “climate change”', x='Count of \"climate change\" in 2016', y='Difference in 2018')+\n",
    "theme(text=element_text(size=10), panel.grid.major = element_blank(), panel.grid.minor = element_blank(),\n",
    "        plot.background=element_rect(fill='white'), panel.background = element_rect(fill='white'), \n",
    "        legend.position=\"none\", axis.line.x = element_line(colour = \"black\", size=0)) +\n",
    "scale_y_continuous(limits=c(-40,20), breaks=seq(-100, 80, 5)) +\n",
    "scale_x_continuous(limits=c(0,35), breaks=seq(0, 150, 5)) + \n",
    "geom_hline(yintercept=0, linetype=\"dashed\", color = \"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FIGURE 5\n",
    "# again, this could be done in a loop to compare multiple terms, but for our purposes, we'll look at \"climate change\"\n",
    "# and resilience\n",
    "i=9\n",
    "j=43\n",
    "#assess term pairing in first\n",
    "print(terms[c(i,j)]) #the terms we're working on right now\n",
    "col<-first[c(i,j)] #from the first timeframe, the term count\n",
    "tcol<-second[c(i,j)] #from the second teimframe, the term count\n",
    "#colcombined<-combined[i] #second - first count, for this term\n",
    "\n",
    "urlsDump<-urls # a temporary variable for our URLs\n",
    "orgsDump<-data.frame(urls$org) # a temporary variable for our URLs\n",
    "\n",
    "#shed zeros - We won't count pages if both terms weren't used on same page\n",
    "zeros<-which(col[,1]==0 & col[,2]==0)\n",
    "col<-col[-c(zeros),]\n",
    "tcol<-tcol[-c(zeros),] #here we are saying that we will eliminate second timeframe urls if in the first time the urls did not have both terms used\n",
    "urlsDump<-urlsDump[-c(zeros),1]\n",
    "orgsDump<-orgsDump[-c(zeros),1]\n",
    "\n",
    "#Here we bring together, for the current term, the first era, second era, and combined counts, for outputting as a CSV\n",
    "combo<-cbind(urlsDump, col, tcol, orgsDump)\n",
    "colnames(combo)<-c(\"url\", \"o_CC\", \"o_R\", \"t_CC\", \"t_R\", \"orgs\")\n",
    "\n",
    "#now subset data and draw arrows\n",
    "#change<-which(combo[,2]-combo[,4]!= 0 & combo[,3]-combo[,5]!= 0) #NOTE: BOTH TERMS HAVE TO CHANGE....i.e. no flat lines. change?\n",
    "dir<-which(combo[,2]-combo[,4]>0 & combo[,3]-combo[,5] <0)\n",
    "#NE: dir<-which(combo[,2]-combo[,4]<0 & combo[,3]-combo[,5] <0)\n",
    "#SW: dir<-which(combo[,2]-combo[,4]>0 & combo[,3]-combo[,5] >0)\n",
    "#SE (resilience decrease, CC increase): dir<-which(combo[,2]-combo[,4]<0 & combo[,3]-combo[,5] >0)\n",
    "#NW: dir<-which(combo[,2]-combo[,4]>0 & combo[,3]-combo[,5] <0)\n",
    "#E:   dir<-which(combo[,2]-combo[,4]<0 & combo[,3]-combo[,5] == 0) \n",
    "#N: dir<-which(combo[,2]-combo[,4]==0 & combo[,3]-combo[,5] < 0) \n",
    "#S: dir<-which(combo[,2]-combo[,4]==0 & combo[,3]-combo[,5] > 0) \n",
    "combo<-combo[c(dir),] #dir orgfilterchange\n",
    "#combo$Dir<-ifelse(combo[,2]-combo[,4]>0, \"NE\", \"NE\")\n",
    "Legend<-factor(combo$Dir)\n",
    "#Legend<-factor(combo$orgs)\n",
    "#orgfilter<-filter(combo, orgs=='WH')\n",
    "#combo<-orgfilter\n",
    "\n",
    "combo<-combo[,c(2:5)]\n",
    "c<-combo %>% group_by(o_CC, o_R, t_CC, t_R) %>%mutate(count = n())\n",
    "c<-unique(c)\n",
    "#f<-factor(c$count/10)\n",
    "\n",
    "p<-ggplot(c,aes(x = o_CC,y = o_R))+\n",
    "geom_point(aes(x = o_CC,y = o_R), size=0, color=\"white\") + \n",
    "geom_point(aes(x = t_CC,y = t_R), size=0, color=\"white\") +\n",
    "scale_y_continuous(limits=c(0,22), expand = c(0,0)) +\n",
    "scale_x_continuous(limits=c(0,22),expand = c(0,0)) + \n",
    "labs(x=\"Count of climate change\", y=\"Count of resilience\")+\n",
    "theme(aspect.ratio=1)\n",
    "\n",
    "p + theme(text=element_text(size=9), panel.grid.major = element_blank(), panel.grid.minor = element_blank(),\n",
    "        panel.background = element_blank(), legend.position=\"none\", \n",
    "        axis.line = element_line(colour = \"grey68\", size=.1)) +\n",
    "geom_segment(aes(x = o_CC,y = o_R,xend = t_CC,yend = t_R, size=3), color=\"black\", arrow=arrow(angle = 30, length = unit(0.12, \"inches\"), ends = \"last\", type = \"open\")) + \n",
    "geom_abline(intercept=0, slope=1, colour=\"grey68\", linetype=2, size=.2) + scale_size(range = c(.1, 1.2),guide=FALSE)  #+ scale_color_manual(values=c(\"#ef8a62\", \"#67a9cf\"))#+  scale_color_brewer(palette=\"Paired\")#+geom_text(aes(label=url),hjust=0, vjust=0, size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### FIGURE 6\n",
    "\n",
    "by.org<-urls%>% group_by(org) %>%summarise(num_of_pages=n()) # summarize all URLs by org (agency)\n",
    "\n",
    "# This could be configured as a loop to go through each term but for our purposes here, we'll only look at \"climate change\"\n",
    "\n",
    "i=9\n",
    "\n",
    "#report by org and count\n",
    "#pctchg<-unlist(combined[i]/first[i])\n",
    "pc<-which(is.na(combined[i]/first[i])) \n",
    "combined.url<-cbind(urls[c(1,3,6,8)], first[i], second[i], combined[i]) #combined.url is only the urls that aren't NA after combined/first. In other words, we exclude 0/0 (0 obama, 0 change) #how many pages was the term on in at least one of the timeframes...\n",
    "combined.url<-combined.url[-c(pc),]\n",
    "colnames(combined.url)<-c(\"url\", \"obama wm\", \"trump wm\", \"org\", \"before\", \"after\",\"diff\")\n",
    "\n",
    "# debug/fishy check\n",
    "fishy.after<-combined.url%>%group_by(after,org)%>%mutate(pages=n())%>%distinct(after,org,pages)\n",
    "fishy.after<-merge(fishy.after, by.org, by='org')\n",
    "\n",
    "# print list of counts\n",
    "listOfCounts<-cbind(terms[i],sum(combined.url$before), sum(combined.url$after), sum(combined.url$diff), 100*(sum(combined.url$diff)/sum(combined.url$before)), nrow(combined.url)) #sum(first[i]), sum(second[i]), sum(combined[i]), 100*(sum(combined[i])/sum(first[i])))\n",
    "#diganostic<-cbind(first[i], second[i], combined[i], urls$`captured url - 0`, urls$`final captured url - t`)\n",
    "\n",
    "# change by term\n",
    "stats<-combined.url%>% group_by(org) %>%summarise(ObamaSum=sum(before), TrumpSum=sum(after), overall_pct_chg = 100*(sum(diff)/sum(before)), OCount=sum(before >0 ), TCount=sum(after>0), num_of_pages=n())\n",
    "stats<-merge(stats, by.org, by = \"org\")\n",
    "stats$pct<-(stats$num_of_pages.x/stats$num_of_pages.y)*100\n",
    "stats$pagepctchg<-((stats$TCount-stats$OCount)/stats$OCount)*100\n",
    "\n",
    "# Put together the full term count including 0s\n",
    "full<-cbind(urls[c(1,3,6,8)], first[i], second[i], combined[i], 100*(combined[i]/first[i]))\n",
    "colnames(full)<-c(\"url\", \"obama wm\", \"trump wm\", \"org\", \"before\", \"after\",\"diff\",\"pctdiff\")\n",
    "full<-merge(full, obamaDocLength, by=\"url\", all.x=TRUE)\n",
    "full<-merge(full, trumpDocLength, by=\"url\", all.x=TRUE)\n",
    "\n",
    "#visualize term data by agency - changes in average use\n",
    "#calculate obama rate of use, trump rate of use\n",
    "stats.viz<-stats\n",
    "stats.viz$Obamadensity<-stats.viz$ObamaSum/stats.viz$num_of_pages.y #rate of use across all agency pages\n",
    "stats.viz$Obamaintensity<-stats.viz$ObamaSum/stats.viz$num_of_pages.x #rate of use across the pages it's used on\n",
    "stats.viz$Trumpdensity<-stats.viz$TrumpSum/stats.viz$num_of_pages.y #rate of use across all agency pages\n",
    "stats.viz$Trumpintensity<-stats.viz$TrumpSum/stats.viz$num_of_pages.x #rate of use across the pages it's used on\n",
    "\n",
    "stats.viz$position[stats.viz$TrumpSum- stats.viz$ObamaSum == 0] = \"No Change\"\n",
    "stats.viz$position[stats.viz$TrumpSum- stats.viz$ObamaSum > 0] = \"Increase\"\n",
    "stats.viz$position[stats.viz$TrumpSum- stats.viz$ObamaSum < 0] = \"Decrease\"\n",
    "stats.viz$position[stats.viz$TrumpSum- stats.viz$ObamaSum == 0] = \"No Change\"\n",
    "\n",
    "#FIGURE 6\n",
    "title<-(\"Climate Change - Average Per Page Use by Agency\")\n",
    "#file<-paste(\"outputs/figures/by term/\",title,\".png\", sep=\"\")  #save\n",
    "p<-ggplot(stats.viz,aes(x = Obamadensity,y = Trumpdensity, label = stats.viz$org))+\n",
    "geom_abline(intercept=0, slope=1, colour=\"black\", size=.3, linetype=\"dashed\") +\n",
    "geom_point(aes(x = Obamadensity,y = Trumpdensity,  color=stats.viz$position), size=4) + \n",
    "scale_x_sqrt(breaks=c(0, .1,.25, .5, 1, 2, 5, 10)) +\n",
    "scale_y_sqrt(breaks=c(0, .1,.25, .5, 1,2, 5, 10)) +\n",
    "labs(x=\"2016\", y=\"2018\", title=title) +\n",
    "geom_text_repel(colour='dark grey', size = 4, box.padding = .75) + \n",
    "scale_colour_manual(values = c(\"Red\", \"Blue\", \"Grey\"))\n",
    "\n",
    "p + theme(text=element_text(size=10), panel.grid.major = element_blank(), panel.grid.minor = element_blank(),\n",
    "         plot.background=element_rect(fill='white'), panel.background = element_rect(fill='white'), \n",
    "         legend.position=\"none\", axis.line = element_line(colour = \"black\", size=0)) \n",
    "#+ scale_color_manual(values=c(\"#ef8a62\", \"#67a9cf\"))#+  scale_color_brewer(palette=\"Paired\")#+geom_text(aes(label=url),hjust=0, vjust=0, size = 2)\n",
    "# ggsave(file, plot=last_plot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#line graph FIGURE 7\n",
    "# ideally the creation of cabinet_counts and cabinet_average would be done _in this script_\n",
    "\n",
    "f<-read_csv(\"outputs/cabinet_average.csv\")\n",
    "f$Term<-factor(f$Term, levels=c(\"climate change\", \"climate\", \"greenhouse gases\", \"clean energy\", \n",
    "                                \"hydraulic fracturing\", \"adaptation\", \"air quality\", \"emissions\", \n",
    "                                \"resilience\", \"sustainability\", \"unconventional gas\", \"unconventional oil\", \n",
    "                                \"energy independence\"))\n",
    "\n",
    "p<-ggplot(data=f, aes(x=Term, y=Average, group=Cabinet)) +\n",
    "  geom_line(aes(color=Cabinet), size=2)+\n",
    "  geom_point(aes(color=Cabinet), size=5) + \n",
    "  geom_abline(intercept=0, slope=0, colour=\"black\", size=.1) +\n",
    "  theme(text=element_text(size=12), \n",
    "        axis.text.x = element_text(angle = 45, hjust = 1), \n",
    "        panel.grid.major = element_blank(), \n",
    "        panel.grid.minor = element_blank(),\n",
    "        panel.background = element_blank(), \n",
    "        legend.position=\"none\",\n",
    "        axis.line = element_line(colour = \"grey68\", size=1)) +\n",
    "  labs(title=\"Cabinet vs. Non-Cabinet Average Change Per Page\", y=\"Change\") +\n",
    "  scale_color_manual(values=c('#5ab4ac','#d8b365')) +\n",
    "  annotate(\"text\", label = \"Cabinet\", x = 1, y = -3, size = 5, colour = \"black\")  +\n",
    "  annotate(\"text\", label = \"Non-Cabinet\", x = 1.5, y = .5, size = 5, colour = \"black\")\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#box and whiskers FIGURE 8\n",
    "# ideally the creation of cabinet_counts and cabinet_average would be done _in this script_\n",
    "\n",
    "f <- read_csv(\"outputs/cabinet_counts.csv\")\n",
    "f$term <- factor(f$term, levels=c(\"climate change\", \"climate\", \n",
    "                                        \"greenhouse gases\", \"clean energy\", \"hydraulic fracturing\", \n",
    "                                        \"adaptation\", \"air quality\", \"emissions\", \"resilience\", \"sustainability\", \n",
    "                                        \"unconventional gas\", \"unconventional oil\", \"energy independence\"))\n",
    "\n",
    "#How many of each change 1->2, 1->4, 3->1 are there?\n",
    "f <- f %>% group_by(term, change, cabinet)%>%mutate(count=n())\n",
    "\n",
    "p <- ggplot(f, aes(x=term, y=change)) +\n",
    "  #geom_dotplot(aes(color=cabinet), binaxis='y', stackdir='center', binwidth = 20, dotsize=.5, position=position_dodge(1)) +\n",
    "  geom_point(aes(shape=\"20\", color=cabinet, size=count), na.rm=TRUE, position=position_dodge(.5))+\n",
    "  scale_size(range = c(3, 10)) +\n",
    "  #stat_boxplot(geom = 'errorbar') +\n",
    "  #geom_boxplot(position=position_dodge(.5)) +\n",
    "  #scale_y_continuous(limits=c(-25,25))\n",
    "  geom_abline(intercept=0, slope=0, colour=\"black\", size=.1) +\n",
    "  theme(text=element_text(size=14), axis.text.x = element_text(angle = 45, hjust = 1),\n",
    "          panel.grid.major = element_blank(), \n",
    "          panel.grid.minor = element_blank(),\n",
    "          panel.background = element_blank(), \n",
    "          legend.position=\"none\", \n",
    "          axis.line = element_line(colour = \"grey68\", size=.1)) +\n",
    "  labs(title=\"Cabinet vs. Non-Cabinet Per Page Changes\", y=\"Change\", x=\"Term\") +\n",
    "  scale_color_manual(values=c('#d8b365','#5ab4ac')) +\n",
    "  annotate(\"text\", angle = 45, hjust=1, label = \"Cabinet\", x = 1, y = 15, size = 3, colour = \"#d8b365\")  +\n",
    "  annotate(\"text\", angle = 45, hjust=1, label = \"Non-Cabinet\", x = 1.5, y = 30, size = 3, colour = '#5ab4ac')\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIGURE 9\n",
    "x <- read_csv(\"outputs/depth/depthR.csv\")\n",
    "colnames(x)<-c(\"Term\", \"Visibility\", \"Percent\", \"Viz\")\n",
    "x <- x[order(-x$Percent),]\n",
    "pal <- c(\"red\", \"blue\")\n",
    "ggplot(x, aes(x=Visibility, y=Percent, alpha=Viz, fill = Percent>0)) + \n",
    "  geom_bar(position=\"dodge\", stat=\"identity\", width = .5) +\n",
    "  scale_fill_manual(values = pal) +\n",
    "  geom_hline(yintercept=0, size=.5, linetype=\"dashed\") +\n",
    "  ggtitle(\"#Differences in Use of 'Climate Change' by Agency and Page Visibility\") + \n",
    "  facet_wrap(~Agency, ncol=3) + #Agency\n",
    "  coord_flip() +\n",
    "  xlab(\"\") +  \n",
    "  scale_x_discrete(breaks=NULL, labels=NULL)+\n",
    "  theme(text=element_text(size=10),panel.background = element_rect(fill='white'), \n",
    "        legend.position=\"none\", axis.text.y=element_blank(), panel.grid.major.y = element_blank(), \n",
    "        panel.grid.minor.y=element_blank(), panel.grid.minor.x=element_blank(), panel.grid.major.x=element_blank()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIGURE 10\n",
    "x <- read_csv(\"outputs/depth/depthAgencyR.csv\") \n",
    "x<-first\n",
    "\n",
    "colnames(x)<-c(\"Agency\", \"Visibility\", \"Percent\", \"Viz\") \n",
    "x <- x[order(-x$Percent),]\n",
    "pal <- c(\"red\", \"blue\")\n",
    "ggplot(x, aes(x=Visibility, y=Percent, alpha=Viz, fill = Percent>0)) + \n",
    "  geom_bar(position=\"dodge\", stat=\"identity\", width = .5) +\n",
    "  scale_fill_manual(values = pal) +\n",
    "  geom_hline(yintercept=0, size=.5, linetype=\"dashed\") +\n",
    "  ggtitle(\"Differences in Use of Terms by Page Visibility\") + \n",
    "  facet_wrap(~Agency, ncol=3) + #Agency\n",
    "  coord_flip() +\n",
    "  xlab(\"\") +  \n",
    "  scale_x_discrete(breaks=NULL, labels=NULL)+\n",
    "  theme(text=element_text(size=10),panel.background = element_rect(fill='white'), \n",
    "        legend.position=\"none\", axis.text.y=element_blank(), panel.grid.major.y = element_blank(), \n",
    "        panel.grid.minor.y=element_blank(), panel.grid.minor.x=element_blank(), panel.grid.major.x=element_blank()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
